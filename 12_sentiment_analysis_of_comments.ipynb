{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Привет, меня зовут Люман Аблаев. Сегодня я проверю твой проект.\n",
    "<br> Дальнейшее общение будет происходить на \"ты\" если это не вызывает никаких проблем.\n",
    "<br> Желательно реагировать на каждый мой комментарий ('исправил', 'не понятно как исправить ошибку', ...)\n",
    "<br> Пожалуйста, не удаляй комментарии ревьюера, так как они повышают качество повторного ревью.\n",
    "\n",
    "Комментарии будут в <font color='green'>зеленой</font>, <font color='blue'>синей</font> или <font color='red'>красной</font> рамках:\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Если все сделано отлично\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Если можно немного улучшить\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Ошибка:</b> Если требуются исправления. Работа не может быть принята с красными комментариями.\n",
    "</div>\n",
    "\n",
    "\n",
    "<font color='orange' style='font-size:24px; font-weight:bold'>Общее впечатление</font>\n",
    "* Большое спасибо за проделанную работу. Видно, что приложено много усилий.\n",
    "* Радует, что ноутбук хорошо структурирован. Приятно проверять такие работы.\n",
    "- Отлично, что стоп-слова были исключены при векторизации!\n",
    "- Я оставил некоторые советы, обрати на них внимание. Надеюсь они будут полезными или интересными\n",
    "- Ты успешно справилась с задачей машинного обучения для текстов, поздравляю!\n",
    "* Отправляю проект назад, чтобы ты дополнила работу(по желанию) и задала вопросы, если они у тебя есть. Если их нет, то можешь просто отправить проект еще раз и я его зачту.\n",
    "\n",
    "\n",
    "\n",
    "<font color='green'><b>Полезные (и просто интересные) материалы:</b> \\\n",
    "Для работы с текстами используют и другие подходы. Например, сейчас активно используются RNN (LSTM) и трансформеры (BERT и другие с улицы Сезам, например, ELMO). НО! Они не являются панацеей, не всегда они нужны, так как и TF-IDF или Word2Vec + модели из классического ML тоже могут справляться. \\\n",
    "BERT тяжелый, существует много его вариаций для разных задач, есть готовые модели, есть надстройки над библиотекой transformers. Если, обучать BERT на GPU (можно в Google Colab или Kaggle), то должно быть побыстрее.\\\n",
    "https://huggingface.co/transformers/model_doc/bert.html \\\n",
    "https://t.me/renat_alimbekov \\\n",
    "https://colah.github.io/posts/2015-08-Understanding-LSTMs/ - Про LSTM \\\n",
    "https://web.stanford.edu/~jurafsky/slp3/10.pdf - про энкодер-декодер модели, этеншены\\\n",
    "https://pytorch.org/tutorials/beginner/transformer_tutorial.html - официальный гайд\n",
    "по трансформеру от создателей pytorch\\\n",
    "https://transformer.huggingface.co/ - поболтать с трансформером \\\n",
    "Библиотеки: allennlp, fairseq, transformers, tensorflow-text — множествореализованных\n",
    "методов для трансформеров методов NLP \\\n",
    "Word2Vec https://radimrehurek.com/gensim/models/word2vec.html \n",
    "\n",
    "<font color='green'>Пример BERT с GPU:\n",
    "```python\n",
    "%%time\n",
    "from tqdm import notebook\n",
    "batch_size = 2 # для примера возьмем такой батч, где будет всего две строки датасета\n",
    "embeddings = [] \n",
    "for i in notebook.tqdm(range(input_ids.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(input_ids[batch_size*i:batch_size*(i+1)]).cuda() # закидываем тензор на GPU\n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)]).cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.cuda()\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy()) # перевод обратно на проц, чтобы в нумпай кинуть\n",
    "        del batch\n",
    "        del attention_mask_batch\n",
    "        del batch_embeddings\n",
    "        \n",
    "features = np.concatenate(embeddings) \n",
    "```\n",
    "Можно сделать предварительную проверку на наличие GPU.\\\n",
    "Например, так: ```device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")```\\\n",
    "Тогда вместо .cuda() нужно писать .to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Подготовка-текста\" data-toc-modified-id=\"Подготовка-текста-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Подготовка текста</a></span></li><li><span><a href=\"#Разбиение-на-выборки\" data-toc-modified-id=\"Разбиение-на-выборки-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Разбиение на выборки</a></span></li><li><span><a href=\"#Векторизация\" data-toc-modified-id=\"Векторизация-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Векторизация</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dummy-Classifier\" data-toc-modified-id=\"Dummy-Classifier-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Dummy Classifier</a></span></li><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#DecisionTreeClassifier\" data-toc-modified-id=\"DecisionTreeClassifier-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>DecisionTreeClassifier</a></span></li><li><span><a href=\"#CatBoostClassifier\" data-toc-modified-id=\"CatBoostClassifier-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>CatBoostClassifier</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b>  спасибо за описание проекта\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from pymystem3 import Mystem\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import shuffle\n",
    "import time\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Отлично, что все импорты собраны в верхней части ноутбука! Если у того, кто будет запускать твой ноутбук будут отсутствовать некоторые библиотеки, то он это увидит сразу, а не в процессе!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.101679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.302226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic\n",
       "count  159571.000000\n",
       "mean        0.101679\n",
       "std         0.302226\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         1.000000"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загруженные данные соответсвуют заданию. Пропущенных значений нет. Доля токсичных комментариев всего 0,1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Данные загружены и осмотрены\n",
    "</div>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет:</b> В задачах классификации, всегда желательно проверять дисбаланс классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На примере первых комментариев, можно видеть, что в комментариях встречаются знаки припенания и заглавные буквы, готовя текст к анализу лучше избавимся от этого и лемматизируем его. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mystem()\n",
    "def lemmatize_(text):\n",
    "    text = text.lower()\n",
    "    lemms = \"\".join(m.lemmatize(text))\n",
    "    clear_text = re.sub(r'[^a-zA-Z]', ' ', lemms) \n",
    "    return \" \".join(clear_text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he matches this background colour i m se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "\n",
       "                                           lemm_text  \n",
       "0  explanation why the edits made under my userna...  \n",
       "1  d aww he matches this background colour i m se...  \n",
       "2  hey man i m really not trying to edit war it s...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemm_text'] = df['text'].apply(lemmatize_)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Очистку желательно было провести до лемматизации. Иначе, слова с точкой не лемматизируются.\n",
    "    </div>\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех: </b> Приятно видеть результаты до/после\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбиение на выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем стратификацию выборок по признаку токсичности комментариев, так как у нас есть сильный дисбаланс классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df['lemm_text']\n",
    "target = df['toxic']\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, stratify= target, test_size=0.4, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислим TF-IDF для нашего корпуса текстов. Укажиv стоп-слова. Векторизатор будем обучать только на тренировочной выборке, чтобы модель не знала заранее частотность слов в тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = count_tf_idf.fit_transform(features_train.values.astype('U'))\n",
    "\n",
    "features_test = count_tf_idf.transform(features_test.values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95742, 125904)\n",
      "(63829, 125904)\n"
     ]
    }
   ],
   "source": [
    "print(features_train.shape)\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Молодец, что обучила векторизатор только на тренировочной чатси данных. Это уменьшает переобучение.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Dummy Classifier на тренировочной выборке 0.10643464184540671\n"
     ]
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(random_state=12345, strategy=\"stratified\")\n",
    "\n",
    "dummy_clf.fit(features_train, target_train)\n",
    "\n",
    "print('F1 Dummy Classifier на тренировочной выборке', f1_score(target_train, dummy_clf.predict(features_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Dummy Classifier на тестовой выборке 0.10680644181099971\n",
      "CPU times: user 40.7 ms, sys: 1.51 ms, total: 42.2 ms\n",
      "Wall time: 49.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0494692325592041"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "start_time = time.time()\n",
    "print('F1 Dummy Classifier на тестовой выборке', f1_score(target_test, dummy_clf.predict(features_test)))\n",
    "\n",
    "time_dm = (time.time() - start_time)\n",
    "time_dm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 логистической регрессии на тренировочной выборке 0.8439373601789709\n",
      "CPU times: user 6.85 s, sys: 4.85 s, total: 11.7 s\n",
      "Wall time: 11.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11.796871185302734"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "start_time = time.time()\n",
    "\n",
    "model_lr = LogisticRegression(class_weight='balanced')\n",
    "model_lr.fit(features_train, target_train)\n",
    "\n",
    "print('F1 логистической регрессии на тренировочной выборке', f1_score(target_train, model_lr.predict(features_train)))\n",
    "\n",
    "time_lr = (time.time() - start_time)\n",
    "time_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train_f1 = cross_val_score(model_lr, \n",
    "                      features_train, \n",
    "                      target_train, \n",
    "                      cv=3, \n",
    "                      scoring='f1').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 логистической регрессии на тестовой выборке 0.7513606613847743\n",
      "CPU times: user 31.5 ms, sys: 533 µs, total: 32 ms\n",
      "Wall time: 46 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04588580131530762"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "start_time = time.time()\n",
    "print('F1 логистической регрессии на тестовой выборке', f1_score(target_test, model_lr.predict(features_test)))\n",
    "\n",
    "time_lr_pred = (time.time() - start_time)\n",
    "time_lr_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Тут можно было подобрать параметр C.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "start_time = time.time()\n",
    "\n",
    "hyperparam = {'max_depth': np.arange(30,51,2),\n",
    "              'min_samples_split': np.arange(2, 3, 1)}\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=12345,\n",
    "                                    class_weight='balanced')\n",
    "\n",
    "model_DT = GridSearchCV(tree, hyperparam, scoring='f1', cv=3)\n",
    "\n",
    "model_DT.fit(features_train, target_train)\n",
    "\n",
    "\n",
    "print('F1 дерева решений на тренировочной выборке',model_DT.best_score_)\n",
    "\n",
    "time_dt = (time.time() - start_time)\n",
    "time_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "start_time = time.time()\n",
    "\n",
    "print('F1 дерева решений на тестовой выборке', f1_score(target_test, model_DT.predict(features_test)))\n",
    "\n",
    "time_dt_pred = (time.time() - start_time)\n",
    "time_dt_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_pos_weight = round((len(target_train[target_train == 0]) / \n",
    "                          len(target_train[target_train == 1])), 3)\n",
    "scale_pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.12597\n",
      "0:\tlearn: 0.4205739\ttest: 0.4205739\tbest: 0.4205739 (0)\ttotal: 5.46s\tremaining: 1h 30m 59s\n",
      "100:\tlearn: 0.8565752\ttest: 0.8565752\tbest: 0.8565752 (100)\ttotal: 7m 26s\tremaining: 1h 6m 11s\n",
      "200:\tlearn: 0.8930349\ttest: 0.8930349\tbest: 0.8930349 (200)\ttotal: 14m 44s\tremaining: 58m 37s\n",
      "300:\tlearn: 0.9135882\ttest: 0.9135882\tbest: 0.9135882 (300)\ttotal: 22m 3s\tremaining: 51m 14s\n",
      "400:\tlearn: 0.9293899\ttest: 0.9293899\tbest: 0.9293899 (400)\ttotal: 29m 21s\tremaining: 43m 51s\n",
      "500:\tlearn: 0.9385680\ttest: 0.9385680\tbest: 0.9385680 (500)\ttotal: 36m 39s\tremaining: 36m 30s\n",
      "600:\tlearn: 0.9449541\ttest: 0.9449541\tbest: 0.9449541 (600)\ttotal: 43m 57s\tremaining: 29m 11s\n",
      "700:\tlearn: 0.9525564\ttest: 0.9525564\tbest: 0.9526334 (699)\ttotal: 51m 16s\tremaining: 21m 52s\n",
      "800:\tlearn: 0.9642326\ttest: 0.9642326\tbest: 0.9642326 (800)\ttotal: 58m 35s\tremaining: 14m 33s\n",
      "900:\tlearn: 0.9759608\ttest: 0.9759608\tbest: 0.9759608 (900)\ttotal: 1h 5m 55s\tremaining: 7m 14s\n",
      "999:\tlearn: 0.9824302\ttest: 0.9824302\tbest: 0.9824302 (999)\ttotal: 1h 13m 10s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9824302036\n",
      "bestIteration = 999\n",
      "\n",
      "CPU times: user 1h 13min 41s, sys: 1min 37s, total: 1h 15min 19s\n",
      "Wall time: 1h 15min 28s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4528.329458475113"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "start_time = time.time()\n",
    "\n",
    "model_cat = CatBoostClassifier(random_state = 12345, verbose=100, eval_metric='F1',\n",
    "                              scale_pos_weight=scale_pos_weight)\n",
    "\n",
    "\n",
    "\n",
    "model_cat.fit(features_train, target_train, eval_set=(features_train, target_train))\n",
    "\n",
    "\n",
    "time_cb = (time.time() - start_time)\n",
    "time_cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 CatBoost на тестовой выборке 0.7671391379809084\n",
      "CPU times: user 2.51 s, sys: 713 ms, total: 3.22 s\n",
      "Wall time: 3.24 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.2419142723083496"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "start_time = time.time()\n",
    "print('F1 CatBoost на тестовой выборке', f1_score(target_test, model_cat.predict(features_test)))\n",
    "\n",
    "time_cb_pred = (time.time() - start_time)\n",
    "time_cb_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Отлично, что ты попробовала несколько разных моделей и подходов!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> С кросс-валидационными методами нужно быть аккуратне, так как внутри кросс-валидации происходит разбиение выборки на треин и валидацию. Однако, в таком случае векторизатор обучен на всей выборке, а это не совсем корректно. Для избежания такого эффекта можно использовать <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\">пайплайн</a>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Dummy Classifier на тестовой выборке 0.10680644181099971 0.0494692325592041\n",
      "F1 логистической регрессии на тестовой выборке 0.7513606613847743 0.04588580131530762\n",
      "F1 дерева решений на тестовой выборке 0.6144306651634723 0.10628080368041992\n",
      "F1 CatBoostClassifier  на тестовой выборке 0.7671391379809084 3.2419142723083496\n"
     ]
    }
   ],
   "source": [
    "print('F1 Dummy Classifier на тестовой выборке', f1_score(target_test, dummy_clf.predict(features_test)), time_dm)\n",
    "print('F1 логистической регрессии на тестовой выборке', f1_score(target_test, model_lr.predict(features_test)), time_lr_pred)\n",
    "print('F1 дерева решений на тестовой выборке', f1_score(target_test, model_DT.predict(features_test)), time_dt_pred)\n",
    "print('F1 CatBoostClassifier  на тестовой выборке', f1_score(target_test, model_cat.predict(features_test)), time_cb_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самая лучшая модель это Catboost, f1- 0.767 но она ее обучение требует очень много времени. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Приятно видеть  вывод в конце проекта! \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет:</b> Здесь хорошо смотрелась бы информативная таблица\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1650,
    "start_time": "2021-08-04T16:54:04.605Z"
   },
   {
    "duration": 735,
    "start_time": "2021-08-04T16:54:38.779Z"
   },
   {
    "duration": 778,
    "start_time": "2021-08-04T16:59:06.136Z"
   },
   {
    "duration": 33,
    "start_time": "2021-08-04T16:59:09.471Z"
   },
   {
    "duration": 22,
    "start_time": "2021-08-04T16:59:55.977Z"
   },
   {
    "duration": 4,
    "start_time": "2021-08-04T17:04:32.050Z"
   },
   {
    "duration": 350,
    "start_time": "2021-08-04T17:08:33.460Z"
   },
   {
    "duration": 4,
    "start_time": "2021-08-04T17:08:47.896Z"
   },
   {
    "duration": 2762,
    "start_time": "2021-08-04T17:09:24.740Z"
   },
   {
    "duration": 1075,
    "start_time": "2021-08-04T17:09:30.036Z"
   },
   {
    "duration": 10,
    "start_time": "2021-08-04T17:09:56.723Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-04T17:10:49.367Z"
   },
   {
    "duration": 410,
    "start_time": "2021-08-04T17:11:04.034Z"
   },
   {
    "duration": 350,
    "start_time": "2021-08-04T17:11:08.159Z"
   },
   {
    "duration": 356,
    "start_time": "2021-08-04T17:11:15.231Z"
   },
   {
    "duration": 362,
    "start_time": "2021-08-04T17:11:19.210Z"
   },
   {
    "duration": 366,
    "start_time": "2021-08-04T17:11:19.889Z"
   },
   {
    "duration": 1926,
    "start_time": "2021-08-04T17:11:23.447Z"
   },
   {
    "duration": 734,
    "start_time": "2021-08-04T17:11:25.376Z"
   },
   {
    "duration": 27,
    "start_time": "2021-08-04T17:11:26.112Z"
   },
   {
    "duration": 27,
    "start_time": "2021-08-04T17:11:26.141Z"
   },
   {
    "duration": 2740,
    "start_time": "2021-08-04T17:11:34.386Z"
   },
   {
    "duration": 1034,
    "start_time": "2021-08-04T17:11:38.298Z"
   },
   {
    "duration": 17,
    "start_time": "2021-08-04T17:14:10.793Z"
   },
   {
    "duration": 378,
    "start_time": "2021-08-04T17:14:24.184Z"
   },
   {
    "duration": 163322,
    "start_time": "2021-08-04T17:14:54.061Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-04T17:17:43.932Z"
   },
   {
    "duration": 86282,
    "start_time": "2021-08-04T17:17:54.449Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-04T17:20:11.908Z"
   },
   {
    "duration": 60818,
    "start_time": "2021-08-04T17:20:15.537Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-04T17:21:33.018Z"
   },
   {
    "duration": 56529,
    "start_time": "2021-08-04T17:21:33.824Z"
   },
   {
    "duration": 843,
    "start_time": "2021-08-04T17:22:35.988Z"
   },
   {
    "duration": 4,
    "start_time": "2021-08-04T17:24:03.034Z"
   },
   {
    "duration": 152458,
    "start_time": "2021-08-04T17:24:03.769Z"
   },
   {
    "duration": 46,
    "start_time": "2021-08-04T17:28:27.876Z"
   },
   {
    "duration": 125,
    "start_time": "2021-08-04T17:31:01.633Z"
   },
   {
    "duration": 135,
    "start_time": "2021-08-04T17:31:14.578Z"
   },
   {
    "duration": 150,
    "start_time": "2021-08-04T17:31:53.876Z"
   },
   {
    "duration": 121,
    "start_time": "2021-08-04T17:32:46.992Z"
   },
   {
    "duration": 8,
    "start_time": "2021-08-04T17:35:46.278Z"
   },
   {
    "duration": 3,
    "start_time": "2021-08-04T17:35:46.968Z"
   },
   {
    "duration": 114,
    "start_time": "2021-08-04T17:38:47.705Z"
   },
   {
    "duration": 4588,
    "start_time": "2021-08-04T17:38:53.691Z"
   },
   {
    "duration": 8,
    "start_time": "2021-08-04T17:39:19.983Z"
   },
   {
    "duration": 450,
    "start_time": "2021-08-04T17:39:50.634Z"
   },
   {
    "duration": 392,
    "start_time": "2021-08-04T17:39:55.845Z"
   },
   {
    "duration": 351,
    "start_time": "2021-08-04T17:39:56.632Z"
   },
   {
    "duration": 2215,
    "start_time": "2021-08-04T17:40:06.387Z"
   },
   {
    "duration": 751,
    "start_time": "2021-08-04T17:40:08.604Z"
   },
   {
    "duration": 43,
    "start_time": "2021-08-04T17:40:09.357Z"
   },
   {
    "duration": 22,
    "start_time": "2021-08-04T17:40:09.402Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-04T17:40:09.426Z"
   },
   {
    "duration": 549,
    "start_time": "2021-08-04T17:40:09.433Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-04T17:40:18.336Z"
   },
   {
    "duration": 152237,
    "start_time": "2021-08-04T17:40:18.756Z"
   },
   {
    "duration": 145,
    "start_time": "2021-08-04T17:42:51.000Z"
   },
   {
    "duration": 7,
    "start_time": "2021-08-04T17:42:51.148Z"
   },
   {
    "duration": 10,
    "start_time": "2021-08-04T17:42:51.158Z"
   },
   {
    "duration": 16165,
    "start_time": "2021-08-04T17:42:51.171Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-04T17:44:31.752Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-04T17:44:41.184Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-04T17:44:45.519Z"
   },
   {
    "duration": 357,
    "start_time": "2021-08-04T17:44:59.167Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-04T17:45:02.688Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-04T17:45:28.236Z"
   },
   {
    "duration": 174,
    "start_time": "2021-08-04T17:48:31.232Z"
   },
   {
    "duration": 398,
    "start_time": "2021-08-04T17:48:41.005Z"
   },
   {
    "duration": 8803,
    "start_time": "2021-08-04T17:49:01.118Z"
   },
   {
    "duration": 8090,
    "start_time": "2021-08-04T17:49:24.553Z"
   },
   {
    "duration": 52,
    "start_time": "2021-08-04T17:50:35.018Z"
   },
   {
    "duration": 8254,
    "start_time": "2021-08-04T17:51:14.146Z"
   },
   {
    "duration": 366,
    "start_time": "2021-08-04T17:54:35.917Z"
   },
   {
    "duration": 10,
    "start_time": "2021-08-04T17:55:17.489Z"
   },
   {
    "duration": 23368,
    "start_time": "2021-08-04T17:55:22.474Z"
   },
   {
    "duration": 51,
    "start_time": "2021-08-04T17:56:54.610Z"
   },
   {
    "duration": 12,
    "start_time": "2021-08-04T18:11:50.305Z"
   },
   {
    "duration": 11,
    "start_time": "2021-08-04T18:16:01.418Z"
   },
   {
    "duration": 798,
    "start_time": "2021-08-04T18:16:01.952Z"
   },
   {
    "duration": 33,
    "start_time": "2021-08-04T18:16:02.752Z"
   },
   {
    "duration": 22,
    "start_time": "2021-08-04T18:16:02.802Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-04T18:16:03.147Z"
   },
   {
    "duration": 159164,
    "start_time": "2021-08-04T18:16:03.349Z"
   },
   {
    "duration": 203,
    "start_time": "2021-08-04T18:18:42.515Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-04T18:18:42.721Z"
   },
   {
    "duration": 27,
    "start_time": "2021-08-04T18:18:42.730Z"
   },
   {
    "duration": 16543,
    "start_time": "2021-08-04T18:18:42.760Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-04T18:18:59.305Z"
   },
   {
    "duration": 480191,
    "start_time": "2021-08-04T18:18:59.313Z"
   },
   {
    "duration": -151,
    "start_time": "2021-08-04T18:26:59.657Z"
   },
   {
    "duration": -155,
    "start_time": "2021-08-04T18:26:59.663Z"
   },
   {
    "duration": -158,
    "start_time": "2021-08-04T18:26:59.667Z"
   },
   {
    "duration": -160,
    "start_time": "2021-08-04T18:26:59.670Z"
   },
   {
    "duration": -164,
    "start_time": "2021-08-04T18:26:59.675Z"
   },
   {
    "duration": 99,
    "start_time": "2021-08-04T18:29:42.533Z"
   },
   {
    "duration": 16668,
    "start_time": "2021-08-04T18:30:00.661Z"
   },
   {
    "duration": 4,
    "start_time": "2021-08-04T18:30:17.332Z"
   },
   {
    "duration": 369,
    "start_time": "2021-08-04T18:31:08.146Z"
   },
   {
    "duration": 12,
    "start_time": "2021-08-04T18:31:30.013Z"
   },
   {
    "duration": 72,
    "start_time": "2021-08-04T18:31:34.973Z"
   },
   {
    "duration": 407175,
    "start_time": "2021-08-04T18:31:42.247Z"
   },
   {
    "duration": -81,
    "start_time": "2021-08-04T18:38:29.506Z"
   },
   {
    "duration": -83,
    "start_time": "2021-08-04T18:38:29.509Z"
   },
   {
    "duration": -85,
    "start_time": "2021-08-04T18:38:29.513Z"
   },
   {
    "duration": -87,
    "start_time": "2021-08-04T18:38:29.516Z"
   },
   {
    "duration": -89,
    "start_time": "2021-08-04T18:38:29.519Z"
   },
   {
    "duration": 302,
    "start_time": "2021-08-04T18:44:55.519Z"
   },
   {
    "duration": 738,
    "start_time": "2021-08-04T18:44:55.824Z"
   },
   {
    "duration": 39,
    "start_time": "2021-08-04T18:44:56.565Z"
   },
   {
    "duration": 29,
    "start_time": "2021-08-04T18:44:56.607Z"
   },
   {
    "duration": 13,
    "start_time": "2021-08-04T18:44:56.639Z"
   },
   {
    "duration": 153022,
    "start_time": "2021-08-04T18:44:56.654Z"
   },
   {
    "duration": 173,
    "start_time": "2021-08-04T18:47:29.680Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-04T18:47:29.856Z"
   },
   {
    "duration": 45,
    "start_time": "2021-08-04T18:47:29.864Z"
   },
   {
    "duration": 16899,
    "start_time": "2021-08-04T18:47:29.912Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-04T18:47:46.813Z"
   },
   {
    "duration": 45,
    "start_time": "2021-08-04T18:47:46.821Z"
   },
   {
    "duration": 58,
    "start_time": "2021-08-04T18:47:46.869Z"
   },
   {
    "duration": 848549,
    "start_time": "2021-08-04T18:47:46.929Z"
   },
   {
    "duration": -66,
    "start_time": "2021-08-04T19:06:35.939Z"
   },
   {
    "duration": -54,
    "start_time": "2021-08-04T19:06:35.955Z"
   },
   {
    "duration": -54,
    "start_time": "2021-08-04T19:06:35.960Z"
   },
   {
    "duration": -54,
    "start_time": "2021-08-04T19:06:35.965Z"
   },
   {
    "duration": -55,
    "start_time": "2021-08-04T19:06:35.970Z"
   },
   {
    "duration": -54,
    "start_time": "2021-08-04T19:06:35.973Z"
   },
   {
    "duration": -54,
    "start_time": "2021-08-04T19:06:35.977Z"
   },
   {
    "duration": -62,
    "start_time": "2021-08-04T19:06:35.989Z"
   },
   {
    "duration": -61,
    "start_time": "2021-08-04T19:06:35.993Z"
   },
   {
    "duration": -63,
    "start_time": "2021-08-04T19:06:35.997Z"
   },
   {
    "duration": -66,
    "start_time": "2021-08-04T19:06:36.001Z"
   },
   {
    "duration": -83,
    "start_time": "2021-08-04T19:06:36.019Z"
   },
   {
    "duration": -85,
    "start_time": "2021-08-04T19:06:36.023Z"
   },
   {
    "duration": -28,
    "start_time": "2021-08-04T19:06:36.027Z"
   },
   {
    "duration": -39,
    "start_time": "2021-08-04T19:06:36.040Z"
   },
   {
    "duration": -42,
    "start_time": "2021-08-04T19:06:36.045Z"
   },
   {
    "duration": -45,
    "start_time": "2021-08-04T19:06:36.049Z"
   },
   {
    "duration": -48,
    "start_time": "2021-08-04T19:06:36.053Z"
   },
   {
    "duration": 13,
    "start_time": "2021-08-04T19:06:52.674Z"
   },
   {
    "duration": 726,
    "start_time": "2021-08-04T19:06:53.613Z"
   },
   {
    "duration": 30,
    "start_time": "2021-08-04T19:06:54.342Z"
   },
   {
    "duration": 20,
    "start_time": "2021-08-04T19:06:55.024Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-04T19:06:57.044Z"
   },
   {
    "duration": 152499,
    "start_time": "2021-08-04T19:06:57.526Z"
   },
   {
    "duration": 158,
    "start_time": "2021-08-04T19:09:30.028Z"
   },
   {
    "duration": 12,
    "start_time": "2021-08-04T19:09:30.189Z"
   },
   {
    "duration": 30,
    "start_time": "2021-08-04T19:09:30.204Z"
   },
   {
    "duration": 16992,
    "start_time": "2021-08-04T19:09:30.236Z"
   },
   {
    "duration": 14,
    "start_time": "2021-08-04T19:09:47.237Z"
   },
   {
    "duration": 100,
    "start_time": "2021-08-04T19:09:47.253Z"
   },
   {
    "duration": 64,
    "start_time": "2021-08-04T19:09:47.359Z"
   },
   {
    "duration": 11806,
    "start_time": "2021-08-04T19:09:47.427Z"
   },
   {
    "duration": 32720,
    "start_time": "2021-08-04T19:09:59.236Z"
   },
   {
    "duration": 54,
    "start_time": "2021-08-04T19:10:31.958Z"
   },
   {
    "duration": 125,
    "start_time": "2021-08-04T19:10:32.015Z"
   },
   {
    "duration": -72,
    "start_time": "2021-08-04T19:10:32.215Z"
   },
   {
    "duration": -76,
    "start_time": "2021-08-04T19:10:32.220Z"
   },
   {
    "duration": -84,
    "start_time": "2021-08-04T19:10:32.230Z"
   },
   {
    "duration": -86,
    "start_time": "2021-08-04T19:10:32.234Z"
   },
   {
    "duration": -95,
    "start_time": "2021-08-04T19:10:32.244Z"
   },
   {
    "duration": 267,
    "start_time": "2021-08-04T19:11:02.429Z"
   },
   {
    "duration": 13,
    "start_time": "2021-08-04T19:11:30.433Z"
   },
   {
    "duration": 248,
    "start_time": "2021-08-04T19:11:35.550Z"
   },
   {
    "duration": 249,
    "start_time": "2021-08-04T19:12:12.447Z"
   },
   {
    "duration": 11,
    "start_time": "2021-08-04T19:12:38.839Z"
   },
   {
    "duration": 259,
    "start_time": "2021-08-04T19:12:44.211Z"
   },
   {
    "duration": 11,
    "start_time": "2021-08-04T19:13:02.764Z"
   },
   {
    "duration": 255,
    "start_time": "2021-08-04T19:13:08.184Z"
   },
   {
    "duration": 4528337,
    "start_time": "2021-08-04T19:28:56.375Z"
   },
   {
    "duration": 3250,
    "start_time": "2021-08-04T20:44:24.715Z"
   },
   {
    "duration": 2832,
    "start_time": "2021-08-04T20:44:27.968Z"
   },
   {
    "duration": 2862,
    "start_time": "2021-08-04T20:47:52.540Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
